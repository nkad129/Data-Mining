{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from itertools import chain, combinations\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data_from_file(input_file):\n",
    "    reader = csv.reader(open(input_file), delimiter = ' ')\n",
    "    data = []\n",
    "    for line in reader:\n",
    "        formatted = []\n",
    "        label = int(line[0])\n",
    "        formatted.append(label)\n",
    "        attributes = line[1:]\n",
    "        for attr in attributes:\n",
    "            key, value = attr.split(':')\n",
    "            formatted.append(int(value))\n",
    "        data.append(formatted)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly sample with replacement for data size equivalent to data extracted. Use 63.2% ?\n",
    "def bootstrap(data):\n",
    "    size = int(0.632 * float(len(data)))\n",
    "    bootstrapped_data = random.choices(data, k=size)\n",
    "    #print(bootstrapped_data)\n",
    "    return bootstrapped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self):\n",
    "        self.attribute = 0\n",
    "        self.attribute_value = 0\n",
    "        self.class_label = 0\n",
    "        self.children = []\n",
    "        self.isLeafNode = 0\n",
    "        \n",
    "    def add(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "    def get_kids(self):\n",
    "        return self.children\n",
    "    \n",
    "    def get_class_label(self):\n",
    "        return self.class_label\n",
    "    \n",
    "    def verify_leaf(self):\n",
    "        return self.isLeafNode\n",
    "    \n",
    "    def get_attribute(self):\n",
    "        return self.attribute\n",
    "    \n",
    "    def get_attribute_value(self):\n",
    "        return self.attribute_value\n",
    "    \n",
    "def create_attribute_list(data_partition):\n",
    "    attribute_list = [i for i in range(1, len(data_partition[0]))]\n",
    "    return attribute_list\n",
    "\n",
    "def check_if_same_class_label(data_partition, counter):\n",
    "    #print(counter, len(counter))\n",
    "    if len(counter) == 1:\n",
    "        return counter.most_common(1)[0][0]\n",
    "    return 0\n",
    "\n",
    "def majority_vote_class_label(data_partition, counter):\n",
    "    #Returns a list of tuples, get 0 entry of first tuple for most common class label.\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "#Makes a leaf node with indicated class node for decision tree.\n",
    "def makeLeafNode(target_node, class_label):\n",
    "    target_node.class_label = class_label\n",
    "    target_node.isLeafNode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_split_attribute(data_partition, attribute_list, num_values_in_attributes):\n",
    "    #Get number of tuples in data partition and list of class labels for dataset.\n",
    "    gini_attribute_splits = []\n",
    "    num_data = len(data_partition)\n",
    "    num_class_labels = [data_partition[x][0] for x in range(num_data)]\n",
    "    \n",
    "    #Random Forest modification: Random Attribute Selection. Choose a sample of n**0.5 attributes from overall list to \n",
    "    #decide to split on.\n",
    "    k = math.floor(len(attribute_list) ** 0.5)\n",
    "    random_attributes = random.sample(attribute_list, k)\n",
    "    #print('random attribute selection: ', random_attributes)\n",
    "    #random_attributes = attribute_list\n",
    "    \n",
    "    #Go through each individual attribute. Start at column 1, since column 0 is class labels.\n",
    "    for i in random_attributes:\n",
    "        gini_values = []\n",
    "        attribute_value_data_count = []\n",
    "        #Get all values for attribute i. Make a Counter class dictionary out of it (keys are attribute values, value is count of them.)\n",
    "        attribute_values = [data_partition[x][i] for x in range(num_data)]\n",
    "        attribute_value_counter = Counter(attribute_values)\n",
    "        #print('attribute values:', attribute_values, 'attribute value counter: ', attribute_value_counter)\n",
    "        #attribute_values = num_values_in_attributes[i - 1]\n",
    "        #Go through each unique value in attribute i. \n",
    "        for value in attribute_value_counter.keys():\n",
    "        #for value in range_len(1, attribute_values + 1):\n",
    "            #If value matches attribute i, then append to sublist. The count of ALL values in attribute i should equal to length of dataset input.\n",
    "            value_sublist = [[attribute_values[a], num_class_labels[a]] for a in range(len(attribute_values)) if attribute_values[a] == value]\n",
    "            #print('length of attribute_values: ', len(attribute_values), 'length of class labels: ', len(num_class_labels))\n",
    "            #print('current value in attribute: ', value, 'Values sublist:', value_sublist)\n",
    "            #value_sublist = []\n",
    "            count = len(value_sublist)\n",
    "            #print('length of sublist: ', count)\n",
    "            #Get all class labels and make counter out of them. Will use for calculating gini index.\n",
    "            value_class_labels_counter = Counter([value_sublist[a][1] for a in range(count)])\n",
    "            attribute_value_data_count.append(count)\n",
    "            #Calculate gini index of this value for attribute i, for all possible class labels.\n",
    "            local_gini_index = 1 - sum((local_label/count)**2 for local_label in value_class_labels_counter.values())\n",
    "            gini_values.append(local_gini_index)\n",
    "            \n",
    "        gini_split = sum((attribute_value_data_count[a]/num_data) * gini_values[a] for a in range(len(attribute_value_data_count))) \n",
    "        gini_attribute_splits.append(gini_split)\n",
    "\n",
    "    smallest_gini_value = min(gini_attribute_splits)\n",
    "    index = gini_attribute_splits.index(smallest_gini_value)\n",
    "    random_attribute_select = random_attributes[index]\n",
    "    #print('gini attribute splits: ', gini_attribute_splits, 'index: ', index, 'randomly selected attribute: ', random_attribute_select)\n",
    "    return random_attribute_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates decision tree to use on the testing set. No continuous values used, as stated in HW4, only discrete.\n",
    "#Need to prune tree after generating tree in order to address overfitting issues.\n",
    "def generate_decision_tree(data_partition, attribute_list, depth_lim = 0):\n",
    "    currNode = Node()\n",
    "    #currNode.attribute_list = attribute_list\n",
    "    class_labels = [data_partition[x][0] for x in range(len(data_partition))]\n",
    "    labels_counter = Counter(class_labels)\n",
    "    #print('Current attribute list: ', attribute_list)\n",
    "    #Get number of variables for each attribute, so we can use them to generate appropriate number of branches. Starts at\n",
    "    #index 1, with class labels with index 0 in the list.\n",
    "    num_values_in_attributes = []\n",
    "    for i in range(len(data[0])):\n",
    "        values = Counter([data[x][i] for x in range(len(data))])\n",
    "        num_values_in_attributes.append(len(values))\n",
    "    #print(num_values_in_attributes)\n",
    "    \n",
    "    #Step 1: If class label on tuples are same, return currNode as leafnode with class label.\n",
    "    class_label = check_if_same_class_label(data_partition, labels_counter)\n",
    "    if(class_label != 0):\n",
    "        #print('reached same class label base case')\n",
    "        makeLeafNode(currNode, class_label)\n",
    "        return currNode\n",
    "    \n",
    "    #Step 2: If attribute list is empty, then do majority vote for class label, then return currNode as leafnode with class label.\n",
    "    if not attribute_list or depth_lim == 5:\n",
    "        class_label = majority_vote_class_label(data_partition, labels_counter)\n",
    "        #print('reached empty attribute label base case. Majority class vote label is: ', class_label)\n",
    "        makeLeafNode(currNode, class_label)\n",
    "        return currNode\n",
    "    \n",
    "    #Step 3: Use gini impurity to choose best splitting criterion.\n",
    "    best_split_attr = get_best_split_attribute(data_partition, attribute_list, num_values_in_attributes)\n",
    "    currNode.attribute = best_split_attr\n",
    "    \n",
    "    #Step 4: Delete attribute from tree, as we do not want to use it again.\n",
    "    #attr_data_split = Counter([data_partition[x][best_split_attr] for x in range(len(data_partition))])\n",
    "    #print('best split attribute: ', best_split_attr)\n",
    "    #list_attribute_values = list(attr_data_split.keys())\n",
    "    values_in_curr_attr = num_values_in_attributes[best_split_attr]\n",
    "    range_values = [i for i in range(1, values_in_curr_attr + 1)]\n",
    "    #not_in_list = list(set(range_values) ^ set(list_attribute_values))\n",
    "    #print(values_in_curr_attr)\n",
    "    #print('range values: ', range_values)\n",
    "    #attribute_list.remove(best_split_attr)\n",
    "    #print(attr_data_split)\n",
    "    #print(best_split_attr)\n",
    "    #print(attribute_list)\n",
    "    \n",
    "    for attr_value in range_values:\n",
    "        attr_data_partition = [data_partition[x] for x in range(len(data_partition)) if data_partition[x][best_split_attr] == attr_value]\n",
    "        if(len(attr_data_partition) == 0):\n",
    "            leafNode = Node()\n",
    "            leafNode.isLeafNode = 1\n",
    "            leafNode.attribute_value = attr_value\n",
    "            leafNode.class_label = labels_counter.most_common(1)[0][0]\n",
    "            currNode.add(leafNode)\n",
    "        else:\n",
    "            #kid_attr = list(attribute_list)\n",
    "            nextNode = generate_decision_tree(attr_data_partition, attribute_list, depth_lim+1)\n",
    "            nextNode.attribute_value = attr_value\n",
    "            currNode.add(nextNode)\n",
    "    \n",
    "    #print(vars(currNode))\n",
    "    return currNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class_label(data_tuple, currNode):\n",
    "    #print(vars(currNode))\n",
    "    #Base Case. If not leaf node, the no class label either.\n",
    "    if currNode.verify_leaf():\n",
    "        return currNode.get_class_label()\n",
    "    #Recursive Case. Happens, because it is not a leaf node.\n",
    "    assigned_attr = currNode.get_attribute()\n",
    "    attr_value = data_tuple[assigned_attr]\n",
    "    kids = currNode.get_kids()\n",
    "    kids_list = [vars(kids[a]) for a in range(len(kids))]\n",
    "    target_kid = 0\n",
    "    for a in range(len(kids)):\n",
    "        if kids_list[a]['attribute_value'] == attr_value:\n",
    "            target_kid = kids[a]\n",
    "    #Don't know how to fix this, since the tree can be built without possible attribute values.\n",
    "    #if target_kid == 0:\n",
    "        #return 1\n",
    "    #target_kid = vars(kids[a]) for a in range(len(kids)) if kids_list[a]['attribute_value'] == attr_value\n",
    "    #print(vars(target_kid))\n",
    "    class_label = predict_class_label(data_tuple, target_kid)\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get all predicted labels for data set. Use this to calculate metrics and square.\n",
    "def predict_labels(data_partition, root):\n",
    "    predicted_labels = []\n",
    "    for i, data_tuple in enumerate(data_partition):\n",
    "        #print(data_tuple)\n",
    "        tuple_label = predict_class_label(data_tuple, root)\n",
    "        #Each predicted label has the test set's original class label, and the predicted class label.\n",
    "        predicted_labels.append([data_partition[i][0], tuple_label])\n",
    "        #predicted_labels.sort(key=lambda x: x[0])\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use only for testing sets so we get accurate number of class labels. Looking at you, Nursery test data set.\n",
    "def get_num_class_labels(data):\n",
    "    class_labels = [data[x][0] for x in range(len(data))]\n",
    "    labels_counter = Counter(class_labels)\n",
    "    return list(labels_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fixed to not have Numpy used.\n",
    "def create_confusion(data_partition, predicted_labels, num_labels):\n",
    "    class_labels = [data_partition[x][0] for x in range(len(data_partition))]\n",
    "    labels_counter = Counter(class_labels)\n",
    "    confusion_matrix = [[0] * len(num_labels) for i in range(len(num_labels))] \n",
    "    for labels in predicted_labels:\n",
    "        confusion_matrix[labels[0] - 1][labels[1] - 1] += 1\n",
    "    for index in confusion_matrix:\n",
    "        row = [str(a) for a in index]\n",
    "        print(' '.join(row))\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taken from bagging algorithm in book, chapter 8 page 55. Modified for random forest\n",
    "#With random attribute selection in choosing best splitting criteria.\n",
    "def generate_random_forest(original_data, num_trees):\n",
    "    random_forest = []\n",
    "    for i in range(num_trees):\n",
    "        bootstrap_data = bootstrap(original_data)\n",
    "        attribute_list = create_attribute_list(bootstrap_data)\n",
    "        random_forest.append(generate_decision_tree(bootstrap_data, attribute_list, 0))\n",
    "    #print(random_forest)\n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_predict_labels(test_data, random_forest):\n",
    "    all_predicted_labels = []\n",
    "    rf_predicted_labels = []\n",
    "    #Get ALL predicted labels for test set for random forest.\n",
    "    for tree in random_forest:\n",
    "        all_predicted_labels.append(predict_labels(test_data, tree))\n",
    "    #Use majority voting on the labels.\n",
    "    #To access every data tuple.\n",
    "    #print(len(all_predicted_labels))\n",
    "    #print(len(all_predicted_labels[0]))\n",
    "    #print(all_predicted_labels[0][0][1])\n",
    "    for j in range(len(all_predicted_labels[0])):\n",
    "        #print(list(all_predicted_labels[i][j][0] for i in range(len(all_predicted_labels))))\n",
    "        tuple_pred_label_list = [all_predicted_labels[i][j][1] for i in range(len(all_predicted_labels))]\n",
    "        label_list_counter = Counter(tuple_pred_label_list)\n",
    "        #Majority vote based on counter.\n",
    "        winning_label = label_list_counter.most_common(1)[0][0]\n",
    "        #print(label_list_counter)\n",
    "        #print(winning_label)\n",
    "        #print('majority vote: ', [all_predicted_labels[0][j][0], winning_label])\n",
    "        rf_predicted_labels.append([all_predicted_labels[0][j][0], winning_label])\n",
    "    return rf_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 123\n",
      "50 733\n",
      "[[228, 123], [50, 733]]\n"
     ]
    }
   ],
   "source": [
    "data = extract_data_from_file('led.train')\n",
    "test_data = extract_data_from_file('led.test')\n",
    "num_labels = get_num_class_labels(data)\n",
    "random_forest = generate_random_forest(data, 50)\n",
    "predicted_labels2 = rf_predict_labels(test_data, random_forest)\n",
    "#bootstrap_data = bootstrap(data)\n",
    "#attribute_list = create_attribute_list(bootstrap_data)\n",
    "#root = generate_decision_tree(bootstrap_data, attribute_list)\n",
    "#predicted_labels = predict_labels(test_data, root)\n",
    "confusion_matrix = create_confusion(test_data, predicted_labels2, num_labels)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
