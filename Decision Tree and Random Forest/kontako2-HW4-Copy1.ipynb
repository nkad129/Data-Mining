{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from itertools import chain, combinations\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "import profile \n",
    "\n",
    "def extract_data_from_file(input_file):\n",
    "    reader = csv.reader(open(input_file), delimiter = ' ')\n",
    "    data = []\n",
    "    for line in reader:\n",
    "        formatted = []\n",
    "        label = int(line[0])\n",
    "        formatted.append(label)\n",
    "        attributes = line[1:]\n",
    "        for attr in attributes:\n",
    "            key, value = attr.split(':')\n",
    "            formatted.append(int(value))\n",
    "        data.append(formatted)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic treenode implementation. Each node has its attribute or data, and a list of children Nodes.\n",
    "class Node(object):\n",
    "    def __init__(self):\n",
    "        self.attribute = 0\n",
    "        self.attribute_value = 0\n",
    "        self.class_label = 0\n",
    "        self.children = []\n",
    "        self.isLeafNode = 0\n",
    "        \n",
    "    def add(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "    def get_attribute_list(self):\n",
    "        return self.attribute_list\n",
    "    \n",
    "    def get_kids(self):\n",
    "        return self.children\n",
    "    \n",
    "    def get_class_label(self):\n",
    "        return self.class_label\n",
    "    \n",
    "    def verify_leaf(self):\n",
    "        return self.isLeafNode\n",
    "    \n",
    "    def get_attribute(self):\n",
    "        return self.attribute\n",
    "    \n",
    "    def get_attribute_value(self):\n",
    "        return self.attribute_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_attribute_list(data_partition):\n",
    "    attribute_list = [i for i in range(1, len(data_partition[0]))]\n",
    "    return attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree Step 1: Check is all tuples in the dataset have same class label.\n",
    "#If so, then return the class label number. Else if false, return 0.\n",
    "def check_if_same_class_label(data_partition, counter):\n",
    "    #print(counter, len(counter))\n",
    "    if len(counter) == 1:\n",
    "        return counter.most_common(1)[0][0]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use majority voting to determine a leaf node's designated class label.\n",
    "def majority_vote_class_label(data_partition, counter):\n",
    "    #Returns a list of tuples, get 0 entry of first tuple for most common class label.\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Makes a leaf node with indicated class node for decision tree.\n",
    "def makeLeafNode(target_node, class_label):\n",
    "    target_node.class_label = class_label\n",
    "    target_node.isLeafNode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tested and works. Use to determine the attribute to split the current DecisionTree Node with. Whichever attributes that are still\n",
    "#In the attribute list, the one that gives lowest gini index will lead to greatest impurity reduction. Use it.\n",
    "def get_best_split_attribute(data_partition, attribute_list, num_values_in_attributes):\n",
    "    #Get number of tuples in data partition and list of class labels for dataset.\n",
    "    gini_attribute_splits = []\n",
    "    num_data = len(data_partition)\n",
    "    num_class_labels = [data_partition[x][0] for x in range(num_data)]\n",
    "    \n",
    "    #Go through each individual attribute. Start at column 1, since column 0 is class labels.\n",
    "    for i in attribute_list:\n",
    "        gini_values = []\n",
    "        attribute_value_data_count = []\n",
    "        #Get all values for attribute i. Make a Counter class dictionary out of it (keys are attribute values, value is count of them.)\n",
    "        attribute_values = [data_partition[x][i] for x in range(num_data)]\n",
    "        #attribute_value_counter = Counter(attribute_values)\n",
    "        attribute_value_counter = set(attribute_values)\n",
    "        #print('attribute values:', attribute_values, 'attribute value counter: ', attribute_value_counter)\n",
    "        #attribute_values = num_values_in_attributes[i - 1]\n",
    "        #Go through each unique value in attribute i. \n",
    "        for value in attribute_value_counter:\n",
    "        #for value in range_len(1, attribute_values + 1):\n",
    "            #If value matches attribute i, then append to sublist. The count of ALL values in attribute i should equal to length of dataset input.\n",
    "            value_sublist = [[attribute_values[a], num_class_labels[a]] for a in range(len(attribute_values)) if attribute_values[a] == value]\n",
    "            #print('length of attribute_values: ', len(attribute_values), 'length of class labels: ', len(num_class_labels))\n",
    "            #print('current value in attribute: ', value, 'Values sublist:', value_sublist)\n",
    "            #value_sublist = []\n",
    "            count = len(value_sublist)\n",
    "            #print('length of sublist: ', count)\n",
    "            #Get all class labels and make counter out of them. Will use for calculating gini index.\n",
    "            value_class_labels_counter = Counter([value_sublist[a][1] for a in range(count)])\n",
    "            attribute_value_data_count.append(count)\n",
    "            #Calculate gini index of this value for attribute i, for all possible class labels.\n",
    "            local_gini_index = 1 - sum((local_label/count)**2 for local_label in value_class_labels_counter.values())\n",
    "            gini_values.append(local_gini_index)\n",
    "            \n",
    "        gini_split = sum((attribute_value_data_count[a]/num_data) * gini_values[a] for a in range(len(attribute_value_data_count))) \n",
    "        gini_attribute_splits.append(gini_split)\n",
    "\n",
    "    smallest_gini_value = min(gini_attribute_splits)\n",
    "    index = gini_attribute_splits.index(smallest_gini_value)\n",
    "    #This is off by one. The index should be index - 1? Map the actual attribute numbers to the ginis splits.\n",
    "    #print('gini attribute splits: ', gini_attribute_splits, 'index: ', index, 'attribute: ', attribute_list[index])\n",
    "    return attribute_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates decision tree to use on the testing set. No continuous values used, as stated in HW4, only discrete.\n",
    "#Need to prune tree after generating tree in order to address overfitting issues.\n",
    "def generate_decision_tree(data_partition, attribute_list, depth_lim = 0):\n",
    "    currNode = Node()\n",
    "    #currNode.attribute_list = attribute_list\n",
    "    class_labels = [data_partition[x][0] for x in range(len(data_partition))]\n",
    "    labels_counter = Counter(class_labels)\n",
    "    #print('Current attribute list: ', attribute_list)\n",
    "    #Get number of variables for each attribute, so we can use them to generate appropriate number of branches. Starts at\n",
    "    #index 1, with class labels with index 0 in the list.\n",
    "    num_values_in_attributes = []\n",
    "    for i in range(len(data[0])):\n",
    "        values = Counter([data[x][i] for x in range(len(data))])\n",
    "        num_values_in_attributes.append(len(values))\n",
    "    #print(num_values_in_attributes)\n",
    "    \n",
    "    #Step 1: If class label on tuples are same, return currNode as leafnode with class label.\n",
    "    class_label = check_if_same_class_label(data_partition, labels_counter)\n",
    "    if(class_label != 0):\n",
    "        #print('reached same class label base case')\n",
    "        makeLeafNode(currNode, class_label)\n",
    "        return currNode\n",
    "    \n",
    "    #Step 2: If attribute list is empty, then do majority vote for class label, then return currNode as leafnode with class label.\n",
    "    if not attribute_list or depth_lim == 5:\n",
    "        class_label = majority_vote_class_label(data_partition, labels_counter)\n",
    "        #print('reached empty attribute label base case. Majority class vote label is: ', class_label)\n",
    "        makeLeafNode(currNode, class_label)\n",
    "        return currNode\n",
    "    \n",
    "    #Step 3: Use gini impurity to choose best splitting criterion.\n",
    "    best_split_attr = get_best_split_attribute(data_partition, attribute_list, num_values_in_attributes)\n",
    "    currNode.attribute = best_split_attr\n",
    "    \n",
    "    #Step 4: Delete attribute from tree, as we do not want to use it again.\n",
    "    #attr_data_split = Counter([data_partition[x][best_split_attr] for x in range(len(data_partition))])\n",
    "    #print('best split attribute: ', best_split_attr)\n",
    "    #list_attribute_values = list(attr_data_split.keys())\n",
    "    values_in_curr_attr = num_values_in_attributes[best_split_attr]\n",
    "    range_values = [i for i in range(1, values_in_curr_attr + 1)]\n",
    "    #not_in_list = list(set(range_values) ^ set(list_attribute_values))\n",
    "    #print(values_in_curr_attr)\n",
    "    #print('range values: ', range_values)\n",
    "    attribute_list.remove(best_split_attr)\n",
    "    #print(attr_data_split)\n",
    "    #print(best_split_attr)\n",
    "    #print(attribute_list)\n",
    "    \n",
    "    for attr_value in range_values:\n",
    "        attr_data_partition = [data_partition[x] for x in range(len(data_partition)) if data_partition[x][best_split_attr] == attr_value]\n",
    "        if(len(attr_data_partition) == 0):\n",
    "            leafNode = Node()\n",
    "            leafNode.isLeafNode = 1\n",
    "            leafNode.attribute_value = attr_value\n",
    "            leafNode.class_label = labels_counter.most_common(1)[0][0]\n",
    "            currNode.add(leafNode)\n",
    "        else:\n",
    "            kid_attr = list(attribute_list)\n",
    "            nextNode = generate_decision_tree(attr_data_partition, kid_attr, depth_lim+1)\n",
    "            nextNode.attribute_value = attr_value\n",
    "            currNode.add(nextNode)\n",
    "    \n",
    "    #print(vars(currNode))\n",
    "    return currNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recursive function to use for every tuple in test set, for predictions. Compare against actual labels.\n",
    "def predict_class_label(data_tuple, currNode):\n",
    "    #print(vars(currNode))\n",
    "    #Base Case. If not leaf node, the no class label either.\n",
    "    if currNode.verify_leaf():\n",
    "        return currNode.get_class_label()\n",
    "    #Recursive Case. Happens, because it is not a leaf node.\n",
    "    assigned_attr = currNode.get_attribute()\n",
    "    attr_value = data_tuple[assigned_attr]\n",
    "    kids = currNode.get_kids()\n",
    "    kids_list = [vars(kids[a]) for a in range(len(kids))]\n",
    "    target_kid = 0\n",
    "    for a in range(len(kids)):\n",
    "        if kids_list[a]['attribute_value'] == attr_value:\n",
    "            target_kid = kids[a]\n",
    "    #Don't know how to fix this, since the tree can be built without possible attribute values.\n",
    "    #if target_kid == 0:\n",
    "        #return 1\n",
    "    #target_kid = vars(kids[a]) for a in range(len(kids)) if kids_list[a]['attribute_value'] == attr_value\n",
    "    #print(vars(target_kid))\n",
    "    class_label = predict_class_label(data_tuple, target_kid)\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get all predicted labels for data set. Use this to calculate metrics and square.\n",
    "def predict_labels(data_partition, root):\n",
    "    predicted_labels = []\n",
    "    for i, data_tuple in enumerate(data_partition):\n",
    "        #print(data_tuple)\n",
    "        tuple_label = predict_class_label(data_tuple, root)\n",
    "        #Each predicted label has the test set's original class label, and the predicted class label.\n",
    "        predicted_labels.append([data_partition[i][0], tuple_label])\n",
    "        #predicted_labels.sort(key=lambda x: x[0])\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use only for testing sets so we get accurate number of class labels. Looking at you, Nursery test data set.\n",
    "def get_num_class_labels(data):\n",
    "    class_labels = [data[x][0] for x in range(len(data))]\n",
    "    labels_counter = Counter(class_labels)\n",
    "    #returner = []\n",
    "    #for keys in labels_counter.keys():\n",
    "    #    returner.append(keys)\n",
    "    return list(labels_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion(data_partition, predicted_labels, num_labels):\n",
    "    class_labels = [data_partition[x][0] for x in range(len(data_partition))]\n",
    "    labels_counter = Counter(class_labels)\n",
    "    confusion_matrix = [[0] * len(num_labels) for i in range(len(num_labels))] \n",
    "    for labels in predicted_labels:\n",
    "        confusion_matrix[labels[0] - 1][labels[1] - 1] += 1\n",
    "    for index in confusion_matrix:\n",
    "        row = [str(a) for a in index]\n",
    "        print(' '.join(row))\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Main Code###\n",
    "def main():\n",
    "    test_set = sys.argv[2]\n",
    "    training_set = sys.argv[1]\n",
    "    attribute_list = []\n",
    "    data = extract_data_from_file('nursery.train')\n",
    "    test_data = extract_data_from_file('nursery.test')\n",
    "    num_labels = get_num_class_labels(data)\n",
    "    attribute_list = create_attribute_list(data)\n",
    "    #print(attribute_list, 'attribute list length: ', len(attribute_list))\n",
    "    root = generate_decision_tree(data, attribute_list, 0)\n",
    "    predicted_labels = predict_labels(test_data, root)\n",
    "    #print('predicted labels: ', Counter(predicted_labels))\n",
    "    confusion_matrix = create_confusion(test_data, predicted_labels, num_labels)\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'verify_leaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-f6dceb41a477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#profile.run('main()')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-a482cd32511b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#print(attribute_list, 'attribute list length: ', len(attribute_list))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m#print('predicted labels: ', Counter(predicted_labels))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-00f2c183dea2>\u001b[0m in \u001b[0;36mpredict_labels\u001b[1;34m(data_partition, root)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_tuple\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_partition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#print(data_tuple)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtuple_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_class_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;31m#Each predicted label has the test set's original class label, and the predicted class label.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_partition\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-a15eb33a491c>\u001b[0m in \u001b[0;36mpredict_class_label\u001b[1;34m(data_tuple, currNode)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#target_kid = vars(kids[a]) for a in range(len(kids)) if kids_list[a]['attribute_value'] == attr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#print(vars(target_kid))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mclass_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_class_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_kid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-a15eb33a491c>\u001b[0m in \u001b[0;36mpredict_class_label\u001b[1;34m(data_tuple, currNode)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#target_kid = vars(kids[a]) for a in range(len(kids)) if kids_list[a]['attribute_value'] == attr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#print(vars(target_kid))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mclass_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_class_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_kid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-a15eb33a491c>\u001b[0m in \u001b[0;36mpredict_class_label\u001b[1;34m(data_tuple, currNode)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#print(vars(currNode))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Base Case. If not leaf node, the no class label either.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mcurrNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcurrNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_class_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Recursive Case. Happens, because it is not a leaf node.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'verify_leaf'"
     ]
    }
   ],
   "source": [
    "#profile.run('main()')\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
