{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from itertools import chain, combinations\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "#test Decision Tree confusion matrices, done and optimized.\n",
    "bstedt = [[0, 14, 8], [3, 79, 20], [19, 16, 66]]\n",
    "ntedt = [[1531, 44, 21, 0, 0], [26, 101, 0, 0, 3], [30, 0, 1506, 0, 0], [0, 0, 0, 1605, 0], [0, 0, 0, 0, 0]]\n",
    "ledtedt = [[272, 79], [81, 702]]\n",
    "sstedt = [[128, 28, 51, 61], [35, 99, 57, 54], [45, 44, 121, 22], [54, 48, 23, 130]]\n",
    "\n",
    "#train Decision Tree confusion matrices, done and optimized.\n",
    "bstrdt = [[27, 0, 0], [0, 186, 0], [0, 0, 187]]\n",
    "ntrdt = [[2670, 0, 0, 0, 0], [0, 198, 0, 0, 0], [0, 0, 2508, 0, 0], [0, 0, 0, 2715, 0], [0, 0, 0, 0, 2]]\n",
    "ledtrdt = [[491, 147], [146, 1303]]\n",
    "sstrdt = [[726, 1, 1, 4], [0, 753, 1, 1], [2, 1, 764, 1], [2, 2, 1, 740]]\n",
    "\n",
    "#test Random Forest confusion matrices, done and optimized.\n",
    "bsterf = [[0, 12, 10], [0, 86, 16], [0, 13, 88]]\n",
    "nterf = [[1546, 6, 44, 0, 0], [67, 63, 0, 0, 0], [35, 0, 1501, 0, 0], [0, 0, 0, 1605, 0], [0, 0, 0, 0, 0]]\n",
    "ledterf = [[269, 82], [73, 710]]\n",
    "ssterf = [[182, 5, 37, 44], [8, 174, 25, 38], [23, 22, 183, 4], [25, 24, 3, 203]]\n",
    "\n",
    "#train Random Forest confusion matrices, done and optimized.\n",
    "bstrrf = [[27, 0, 0], [0, 186, 0], [0, 0, 187]]\n",
    "ntrrf = [[2669, 0, 1, 0, 0], [0, 198, 0, 0, 0], [0, 0, 2508, 0, 0], [0, 0, 0, 2715, 0], [0, 0, 0, 0, 2]]\n",
    "ledtrrf = [[491, 147], [146, 1303]]\n",
    "sstrrf = [[732, 0, 0, 0], [0, 755, 0, 0], [0, 0, 768, 0], [0, 0, 0, 745]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overall_accuracy(matrix):\n",
    "    print('overall accuracy of set: ')\n",
    "    total_population = sum(sum(matrix, []))\n",
    "    diagonals = 0\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                diagonals += matrix[i][j]\n",
    "    result = float(diagonals)/float(total_population)\n",
    "    print(\"%.4f\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(matrix):\n",
    "    print('accuracy metric per label: ')\n",
    "    total_population = sum(sum(matrix, []))\n",
    "    for i in range(len(matrix)):\n",
    "        tp_and_tn = 0\n",
    "        true_negative = 0\n",
    "        for j in range(len(matrix)):\n",
    "            if j == i:\n",
    "                tp_and_tn += matrix[j][i]\n",
    "                continue\n",
    "            true_negative += sum(matrix[j])\n",
    "            true_negative -= matrix[j][i]\n",
    "        tp_and_tn += true_negative\n",
    "        if total_population == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        #print('tp and tn: ', tp_and_tn, 'total population: ', total_population)\n",
    "        result = float(tp_and_tn)/float(total_population)\n",
    "        print('& ', \"%.4f\" % result, ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specificity(matrix):\n",
    "    print('specific metric per label: ')\n",
    "    for i in range(len(matrix)):\n",
    "        true_negative = 0\n",
    "        tn_and_fp = 0\n",
    "        for j in range(len(matrix)):\n",
    "            if j == i:\n",
    "                continue\n",
    "            tn_and_fp += sum(matrix[j])\n",
    "            true_negative += sum(matrix[j])\n",
    "            true_negative -= matrix[j][i]\n",
    "        #print('true negative: ', true_negative, 'tn and fp: ', tn_and_fp)\n",
    "        if tn_and_fp == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        result = (float(true_negative)/float(tn_and_fp))\n",
    "        print('& ', \"%.4f\" % result, ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(matrix):\n",
    "    print('sensitivity metric per label: ')\n",
    "    for i in range(len(matrix)):\n",
    "        if float(sum(matrix[i])) == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        result = (float(matrix[i][i]) / float(sum(matrix[i])))\n",
    "        print('& ', \"%.4f\" % result, ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(matrix): \n",
    "    print('precision metric per label: ')\n",
    "    for i in range(len(matrix)):\n",
    "        true_positive = 0\n",
    "        tp_and_fp = 0\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                true_positive += matrix[i][j]\n",
    "            tp_and_fp += matrix[j][i]\n",
    "        if tp_and_fp == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        result = (float(true_positive)/float(tp_and_fp))\n",
    "        print('& ', \"%.4f\" % result, ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(matrix):\n",
    "    print('f1 scores: ')\n",
    "    for i in range(len(matrix)):\n",
    "        if float(sum(matrix[i])) == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        sens = (float(matrix[i][i]) / float(sum(matrix[i])))\n",
    "        \n",
    "        true_positive = 0\n",
    "        tp_and_fp = 0\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                true_positive += matrix[i][j]\n",
    "            tp_and_fp += matrix[j][i]\n",
    "        if tp_and_fp == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        prec = (float(true_positive)/float(tp_and_fp))\n",
    "        if prec+sens == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        f1 = (2*prec*sens)/(prec+sens)\n",
    "        print('& ', \"%.4f\" % f1, ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fb(matrix, beta):\n",
    "    print('fb scores: ', beta)\n",
    "    for i in range(len(matrix)):\n",
    "        if float(sum(matrix[i])) == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        sens = (float(matrix[i][i]) / float(sum(matrix[i])))\n",
    "        \n",
    "        true_positive = 0\n",
    "        tp_and_fp = 0\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                true_positive += matrix[i][j]\n",
    "            tp_and_fp += matrix[j][i]\n",
    "        if tp_and_fp == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        prec = (float(true_positive)/float(tp_and_fp))\n",
    "        if prec+sens == 0:\n",
    "            print('& ', 0.0)\n",
    "            continue\n",
    "        result = ((1+(beta**2))*prec*sens)/((beta**2)*prec+sens)\n",
    "        print('& ', \"%.4f\" % result, ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy of set: \n",
      "1.0000\n",
      "accuracy metric per label: \n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  sensitivity metric per label: \n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  precision metric per label: \n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  specific metric per label: \n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  f1 scores: \n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  fb scores:  0.5\n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  fb scores:  2\n",
      "&  1.0000  &  1.0000  &  1.0000  &  1.0000  "
     ]
    }
   ],
   "source": [
    "#need to test all metrics for both training and test data sets.\n",
    "#data = extract_data_from_file('balance.scale.train')\n",
    "#test_data = extract_data_from_file('balance.scale.test')\n",
    "#attribute_list = create_attribute_list(data)\n",
    "#root = generate_decision_tree(data, attribute_list)\n",
    "#predicted_labels = predict_labels(test_data, root)\n",
    "#matrix = create_confusion(test_data, predicted_labels)\n",
    "matrix = sstrrf\n",
    "overall_accuracy(matrix)\n",
    "accuracy(matrix)\n",
    "recall(matrix)\n",
    "precision(matrix)\n",
    "specificity(matrix)\n",
    "f1_score(matrix)\n",
    "fb(matrix, 0.5)\n",
    "fb(matrix, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
